{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Type Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Data**\n",
    "<br>\n",
    "This dataset is about ride sharing, it contains information about each ride trip.<br>\n",
    "<br>information available are:<br>\n",
    "- rideID\n",
    "- duration\n",
    "- source station ID\n",
    "- souce station name\n",
    "- destination station ID\n",
    "- destination station name \n",
    "- bike IDF\n",
    "- user type\n",
    "- user birth year\n",
    "- user gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>duration</th>\n",
       "      <th>station_A_id</th>\n",
       "      <th>station_A_name</th>\n",
       "      <th>station_B_id</th>\n",
       "      <th>station_B_name</th>\n",
       "      <th>bike_id</th>\n",
       "      <th>user_type</th>\n",
       "      <th>user_birth_year</th>\n",
       "      <th>user_gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12 minutes</td>\n",
       "      <td>81</td>\n",
       "      <td>Berry St at 4th St</td>\n",
       "      <td>323</td>\n",
       "      <td>Broadway at Kearny</td>\n",
       "      <td>5480</td>\n",
       "      <td>2</td>\n",
       "      <td>1959</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>24 minutes</td>\n",
       "      <td>3</td>\n",
       "      <td>Powell St BART Station (Market St at 4th St)</td>\n",
       "      <td>118</td>\n",
       "      <td>Eureka Valley Recreation Center</td>\n",
       "      <td>5193</td>\n",
       "      <td>2</td>\n",
       "      <td>1965</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8 minutes</td>\n",
       "      <td>67</td>\n",
       "      <td>San Francisco Caltrain Station 2  (Townsend St...</td>\n",
       "      <td>23</td>\n",
       "      <td>The Embarcadero at Steuart St</td>\n",
       "      <td>3652</td>\n",
       "      <td>3</td>\n",
       "      <td>1993</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4 minutes</td>\n",
       "      <td>16</td>\n",
       "      <td>Steuart St at Market St</td>\n",
       "      <td>28</td>\n",
       "      <td>The Embarcadero at Bryant St</td>\n",
       "      <td>1883</td>\n",
       "      <td>1</td>\n",
       "      <td>1979</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11 minutes</td>\n",
       "      <td>22</td>\n",
       "      <td>Howard St at Beale St</td>\n",
       "      <td>350</td>\n",
       "      <td>8th St at Brannan St</td>\n",
       "      <td>4626</td>\n",
       "      <td>2</td>\n",
       "      <td>1994</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    duration  station_A_id  \\\n",
       "0           0  12 minutes            81   \n",
       "1           1  24 minutes             3   \n",
       "2           2   8 minutes            67   \n",
       "3           3   4 minutes            16   \n",
       "4           4  11 minutes            22   \n",
       "\n",
       "                                      station_A_name  station_B_id  \\\n",
       "0                                 Berry St at 4th St           323   \n",
       "1       Powell St BART Station (Market St at 4th St)           118   \n",
       "2  San Francisco Caltrain Station 2  (Townsend St...            23   \n",
       "3                            Steuart St at Market St            28   \n",
       "4                              Howard St at Beale St           350   \n",
       "\n",
       "                    station_B_name  bike_id  user_type  user_birth_year  \\\n",
       "0               Broadway at Kearny     5480          2             1959   \n",
       "1  Eureka Valley Recreation Center     5193          2             1965   \n",
       "2    The Embarcadero at Steuart St     3652          3             1993   \n",
       "3     The Embarcadero at Bryant St     1883          1             1979   \n",
       "4             8th St at Brannan St     4626          2             1994   \n",
       "\n",
       "  user_gender  \n",
       "0        Male  \n",
       "1        Male  \n",
       "2        Male  \n",
       "3        Male  \n",
       "4        Male  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "filepath = \"D:/cleaning_data/data/ride_sharing_new.csv\"\n",
    "ride_sharing = pd.read_csv(filepath)\n",
    "ride_sharing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ride Duration**\n",
    "<br>\n",
    "\n",
    "The very first thing to spot as a data analyst, is the duration column values, as you can see the values contain \"minutes\", which is not what it should be, we need this to be pure `numerical` data type, not `string`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        12 minutes\n",
       "1        24 minutes\n",
       "2         8 minutes\n",
       "3         4 minutes\n",
       "4        11 minutes\n",
       "            ...    \n",
       "25755    11 minutes\n",
       "25756    10 minutes\n",
       "25757    14 minutes\n",
       "25758    14 minutes\n",
       "25759    29 minutes\n",
       "Name: duration, Length: 25760, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ride_sharing['duration']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's handle this!**\n",
    "<br>\n",
    "\n",
    "**1. First:** remove the text minutes from every value\n",
    "   - we will use the function `strip` from the `str` module\n",
    "   - and store the new value in a new column: `duration_trim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        12 \n",
       "1        24 \n",
       "2         8 \n",
       "3         4 \n",
       "4        11 \n",
       "        ... \n",
       "25755    11 \n",
       "25756    10 \n",
       "25757    14 \n",
       "25758    14 \n",
       "25759    29 \n",
       "Name: duration_trim, Length: 25760, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ride_sharing['duration_trim'] = ride_sharing['duration'].str.strip('minutes')\n",
    "ride_sharing['duration_trim']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Second:** convert the data type to integer\n",
    "- we will apply the `astype` method into `duration_trim`\n",
    "- and store the new values in a new column: `duration_time`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        12\n",
       "1        24\n",
       "2         8\n",
       "3         4\n",
       "4        11\n",
       "         ..\n",
       "25755    11\n",
       "25756    10\n",
       "25757    14\n",
       "25758    14\n",
       "25759    29\n",
       "Name: duration_time, Length: 25760, dtype: int32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert duration to integer\n",
    "ride_sharing['duration_time'] = ride_sharing['duration_trim'].astype('int')\n",
    "ride_sharing['duration_time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Check with an assert statement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ride_sharing['duration_time'].dtype == 'int'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now get insight about the average duration time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Ride Duration:\n",
      "11.389052795031056 minutes\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Ride Duration:\")\n",
    "print(str(ride_sharing['duration_time'].mean()) + ' minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**User Type**\n",
    "<br>\n",
    "Let's have a look at the user type column by calling the `describe` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    25760.000000\n",
       "mean         2.008385\n",
       "std          0.704541\n",
       "min          1.000000\n",
       "25%          2.000000\n",
       "50%          2.000000\n",
       "75%          3.000000\n",
       "max          3.000000\n",
       "Name: user_type, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ride_sharing['user_type'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we called the describe method, it turned out that pandas treates this information as `float`, while its a `categorical` information.\n",
    "<br>\n",
    "Errors with regards to **data type constraints** are very common and important to handle in the data cleaning process.\n",
    "<br>\n",
    "\n",
    "`user_type` shouldn't be treated as `float`, it is **categorical**\n",
    "<br>\n",
    "\n",
    "The `user_type` column contains information on whether a user is taking<br>a free ride and takes on the following values:\n",
    "\n",
    "    1 for free riders.\n",
    "    2 for pay per ride.\n",
    "    3 for monthly subscribers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's fix this and convert the data type column to categorical**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert user_type to category\n",
    "ride_sharing['user_type_cat'] = ride_sharing['user_type'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's check with as assert statement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write an assert statement confirming the change\n",
    "assert ride_sharing['user_type_cat'].dtype == 'category'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's double-check manually**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     25760\n",
       "unique        3\n",
       "top           2\n",
       "freq      12972\n",
       "Name: user_type_cat, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print new summary statistics \n",
    "ride_sharing['user_type_cat'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Great!** \n",
    "<br>\n",
    "Take a look at the new summary statistics, it seems that most users are pay per ride users because the top category is 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problems with data types are solved!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Inconsistent Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Data**\n",
    "<br>\n",
    "This dataset is about airline flights, it contains people survey resposnses about a flight.<br>\n",
    "<br>information available are:<br>\n",
    "- response ID\n",
    "- flight ID\n",
    "- day\n",
    "- airline\n",
    "- destination country\n",
    "- destination region\n",
    "- boarding area\n",
    "- departure time\n",
    "- waiting minutes\n",
    "- how clean the plan was\n",
    "- how safe the flight was\n",
    "- satisfaction level of the flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>day</th>\n",
       "      <th>airline</th>\n",
       "      <th>destination</th>\n",
       "      <th>dest_region</th>\n",
       "      <th>dest_size</th>\n",
       "      <th>boarding_area</th>\n",
       "      <th>dept_time</th>\n",
       "      <th>wait_min</th>\n",
       "      <th>cleanliness</th>\n",
       "      <th>safety</th>\n",
       "      <th>satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1351</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>UNITED INTL</td>\n",
       "      <td>KANSAI</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 91-102</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>115.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>373</td>\n",
       "      <td>Friday</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>SAN JOSE DEL CABO</td>\n",
       "      <td>Canada/Mexico</td>\n",
       "      <td>Small</td>\n",
       "      <td>Gates 50-59</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2820</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>DELTA</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>West US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 40-48</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>Somewhat safe</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1157</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>SOUTHWEST</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>West US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 20-39</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>190.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Somewhat satsified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2992</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>AMERICAN</td>\n",
       "      <td>MIAMI</td>\n",
       "      <td>East US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 50-59</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>559.0</td>\n",
       "      <td>Somewhat clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Somewhat satsified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    id        day      airline        destination    dest_region  \\\n",
       "0           0  1351    Tuesday  UNITED INTL             KANSAI           Asia   \n",
       "1           1   373     Friday       ALASKA  SAN JOSE DEL CABO  Canada/Mexico   \n",
       "2           2  2820   Thursday        DELTA        LOS ANGELES        West US   \n",
       "3           3  1157    Tuesday    SOUTHWEST        LOS ANGELES        West US   \n",
       "4           4  2992  Wednesday     AMERICAN              MIAMI        East US   \n",
       "\n",
       "  dest_size boarding_area   dept_time  wait_min     cleanliness  \\\n",
       "0       Hub  Gates 91-102  2018-12-31     115.0           Clean   \n",
       "1     Small   Gates 50-59  2018-12-31     135.0           Clean   \n",
       "2       Hub   Gates 40-48  2018-12-31      70.0         Average   \n",
       "3       Hub   Gates 20-39  2018-12-31     190.0           Clean   \n",
       "4       Hub   Gates 50-59  2018-12-31     559.0  Somewhat clean   \n",
       "\n",
       "          safety        satisfaction  \n",
       "0        Neutral      Very satisfied  \n",
       "1      Very safe      Very satisfied  \n",
       "2  Somewhat safe             Neutral  \n",
       "3      Very safe  Somewhat satsified  \n",
       "4      Very safe  Somewhat satsified  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"D:/cleaning_data/data/airlines_final.csv\"\n",
    "airlines = pd.read_csv(filepath)\n",
    "airlines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to check for inconsistencies in categorical variables?**\n",
    "<br>\n",
    "Applying the `unique` method on the categorical feature to spot errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's make a list of the categorical features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id', 'day', 'airline', 'destination', 'dest_region',\n",
       "       'dest_size', 'boarding_area', 'dept_time', 'wait_min', 'cleanliness',\n",
       "       'safety', 'satisfaction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['day', 'airline', 'destination', 'dest_region',\n",
    "       'dest_size', 'boarding_area', 'cleanliness',\n",
    "       'safety', 'satisfaction']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build a function to check the unique values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_unique(col):\n",
    "    print('------------------------------------------------------------------')\n",
    "    print(f\"Column: {col}\")\n",
    "    print(airlines[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Looping over the list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "Column: day\n",
      "['Tuesday' 'Friday' 'Thursday' 'Wednesday' 'Saturday' 'Sunday' 'Monday']\n",
      "------------------------------------------------------------------\n",
      "Column: airline\n",
      "['UNITED INTL' 'ALASKA' 'DELTA' 'SOUTHWEST' 'AMERICAN' 'JETBLUE'\n",
      " 'AEROMEXICO' 'AIR CANADA' 'UNITED' 'INTERJET' 'TURKISH AIRLINES'\n",
      " 'AIR FRANCE/KLM' 'HAWAIIAN AIR' 'COPA' 'WOW' 'KOREAN AIR' 'EMIRATES'\n",
      " 'AVIANCA' 'AER LINGUS' 'CATHAY PACIFIC' 'BRITISH AIRWAYS'\n",
      " 'PHILIPPINE AIRLINES' 'LUFTHANSA' 'QANTAS' 'FRONTIER' 'CHINA EASTERN'\n",
      " 'EVA AIR' 'VIRGIN ATLANTIC' 'AIR NEW ZEALAND' 'SINGAPORE AIRLINES'\n",
      " 'AIR CHINA' 'CHINA SOUTHERN' 'ANA ALL NIPPON']\n",
      "------------------------------------------------------------------\n",
      "Column: destination\n",
      "['KANSAI' 'SAN JOSE DEL CABO' 'LOS ANGELES' 'MIAMI' 'NEWARK' 'LONG BEACH'\n",
      " 'MEXICO CITY' 'TORONTO' 'PORTLAND' 'SAN DIEGO' 'BOSTON' 'SPOKANE'\n",
      " 'GUADALAJARA' 'MINNEAPOLIS-ST. PAUL' 'NEW YORK-JFK' 'ISTANBUL'\n",
      " 'BALTIMORE' 'LAS VEGAS' 'SHANGHAI' 'TOKYO-NARITA' 'PARIS-DE GAULLE'\n",
      " 'HONOLULU' 'DALLAS-FT. WORTH' 'PANAMA CITY' 'PHOENIX' 'REYKJAVIK'\n",
      " 'SAN ANTONIO' 'HONG KONG' 'SEOUL' 'DUBAI' \"CHICAGO-O'HARE\" 'INDIANAPOLIS'\n",
      " 'SAN SALVADOR' 'SALT LAKE CITY' 'BEIJING' 'DUBLIN' 'WASHINGTON DC-DULLES'\n",
      " 'LONDON HEATHROW' 'MANILA' 'RALEIGH-DURHAM' 'VANCOUVER' 'MUNICH'\n",
      " 'NEW ORLEANS' 'FRANKFURT' 'SYDNEY' 'KAHULUI' 'AMSTERDAM' 'ATLANTA'\n",
      " 'SEATTLE' 'DETROIT' 'SANTA BARBARA' 'PHILADELPHIA' 'DENVER' 'BAKERSFIELD'\n",
      " 'AUSTIN' 'CALGARY' 'TAIPEI' 'ONTARIO (CALIF)' 'BURBANK' 'CHARLOTTE'\n",
      " 'AUCKLAND' 'SINGAPORE' 'ORLANDO' 'NASHVILLE' 'WUHAN' 'HOUSTON-BUSH'\n",
      " 'FT. LAUDERDALE' 'SANTA ANA' 'EUGENE' 'KANSAS CITY' 'QINGDAO'\n",
      " 'PUERTO VALLARTA']\n",
      "------------------------------------------------------------------\n",
      "Column: dest_region\n",
      "['Asia' 'Canada/Mexico' 'West US' 'East US' 'Midwest US' 'EAST US'\n",
      " 'Middle East' 'Europe' 'eur' 'Central/South America'\n",
      " 'Australia/New Zealand' 'middle east']\n",
      "------------------------------------------------------------------\n",
      "Column: dest_size\n",
      "['Hub' 'Small' '    Hub' 'Medium' 'Large' 'Hub     ' '    Small'\n",
      " 'Medium     ' '    Medium' 'Small     ' '    Large' 'Large     ']\n",
      "------------------------------------------------------------------\n",
      "Column: boarding_area\n",
      "['Gates 91-102' 'Gates 50-59' 'Gates 40-48' 'Gates 20-39' 'Gates 1-12'\n",
      " 'Gates 70-90' 'Gates 60-69']\n",
      "------------------------------------------------------------------\n",
      "Column: cleanliness\n",
      "['Clean' 'Average' 'Somewhat clean' 'Somewhat dirty' 'Dirty']\n",
      "------------------------------------------------------------------\n",
      "Column: safety\n",
      "['Neutral' 'Very safe' 'Somewhat safe' 'Very unsafe' 'Somewhat unsafe']\n",
      "------------------------------------------------------------------\n",
      "Column: satisfaction\n",
      "['Very satisfied' 'Neutral' 'Somewhat satsified' 'Somewhat unsatisfied'\n",
      " 'Very unsatisfied']\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for col in categorical_features:\n",
    "    check_unique(col)\n",
    "print('------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Every thing looks fine, however, there is something wrong with `dest_region` and `dest_size`**\n",
    "<br>\n",
    "**Let's solve them**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dest_region` contains region 'Europe' and region 'eur' which are the same, it also contains 'EAST US' and 'East US' which are also the same but different values because of the upper/lower case.\n",
    "<br>\n",
    "**Let's lower them all**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['asia', 'canada/mexico', 'west us', 'east us', 'midwest us',\n",
       "       'middle east', 'europe', 'eur', 'central/south america',\n",
       "       'australia/new zealand'], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines['dest_region'] = airlines['dest_region'].str.lower() \n",
    "airlines['dest_region'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's replace 'eur' with 'europe'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['asia', 'canada/mexico', 'west us', 'east us', 'midwest us',\n",
       "       'middle east', 'europe', 'central/south america',\n",
       "       'australia/new zealand'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines['dest_region'] = airlines['dest_region'].replace({'eur':'europe'})\n",
    "airlines['dest_region'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**the `dest_region` column solved!**\n",
    "<br>\n",
    "\n",
    "**Let's see `dest_size`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hub', 'Small', '    Hub', 'Medium', 'Large', 'Hub     ',\n",
       "       '    Small', 'Medium     ', '    Medium', 'Small     ',\n",
       "       '    Large', 'Large     '], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines['dest_size'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can tell, there is a **spacing** issue with this columns<br>\n",
    "How can we solve this?<br>\n",
    "...<br>\n",
    "Exactly! with the `strip` method from the `str` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hub', 'Small', 'Medium', 'Large'], dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines['dest_size'] = airlines['dest_size'].str.strip()\n",
    "airlines['dest_size'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inconsistent categories issue has been solved!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Cross Field Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-Field Validation is the use of multiple fields in your dataset to sanity check the integrity of your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cust_id</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>Age</th>\n",
       "      <th>acct_amount</th>\n",
       "      <th>inv_amount</th>\n",
       "      <th>fund_A</th>\n",
       "      <th>fund_B</th>\n",
       "      <th>fund_C</th>\n",
       "      <th>fund_D</th>\n",
       "      <th>account_opened</th>\n",
       "      <th>last_transaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>870A9281</td>\n",
       "      <td>1962-06-09</td>\n",
       "      <td>58</td>\n",
       "      <td>63523.31</td>\n",
       "      <td>51295</td>\n",
       "      <td>30105.0</td>\n",
       "      <td>4138.0</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>15632.0</td>\n",
       "      <td>02-09-18</td>\n",
       "      <td>22-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>166B05B0</td>\n",
       "      <td>1962-12-16</td>\n",
       "      <td>58</td>\n",
       "      <td>38175.46</td>\n",
       "      <td>15050</td>\n",
       "      <td>4995.0</td>\n",
       "      <td>938.0</td>\n",
       "      <td>6696.0</td>\n",
       "      <td>2421.0</td>\n",
       "      <td>28-02-19</td>\n",
       "      <td>31-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>BFC13E88</td>\n",
       "      <td>1990-09-12</td>\n",
       "      <td>34</td>\n",
       "      <td>59863.77</td>\n",
       "      <td>24567</td>\n",
       "      <td>10323.0</td>\n",
       "      <td>4590.0</td>\n",
       "      <td>8469.0</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>25-04-18</td>\n",
       "      <td>02-04-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>F2158F66</td>\n",
       "      <td>1985-11-03</td>\n",
       "      <td>35</td>\n",
       "      <td>84132.10</td>\n",
       "      <td>23712</td>\n",
       "      <td>3908.0</td>\n",
       "      <td>492.0</td>\n",
       "      <td>6482.0</td>\n",
       "      <td>12830.0</td>\n",
       "      <td>07-11-17</td>\n",
       "      <td>08-11-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7A73F334</td>\n",
       "      <td>1990-05-17</td>\n",
       "      <td>30</td>\n",
       "      <td>120512.00</td>\n",
       "      <td>93230</td>\n",
       "      <td>12158.4</td>\n",
       "      <td>51281.0</td>\n",
       "      <td>13434.0</td>\n",
       "      <td>18383.0</td>\n",
       "      <td>14-05-18</td>\n",
       "      <td>19-07-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   cust_id  birth_date  Age  acct_amount  inv_amount   fund_A  \\\n",
       "0           0  870A9281  1962-06-09   58     63523.31       51295  30105.0   \n",
       "1           1  166B05B0  1962-12-16   58     38175.46       15050   4995.0   \n",
       "2           2  BFC13E88  1990-09-12   34     59863.77       24567  10323.0   \n",
       "3           3  F2158F66  1985-11-03   35     84132.10       23712   3908.0   \n",
       "4           4  7A73F334  1990-05-17   30    120512.00       93230  12158.4   \n",
       "\n",
       "    fund_B   fund_C   fund_D account_opened last_transaction  \n",
       "0   4138.0   1420.0  15632.0       02-09-18         22-02-19  \n",
       "1    938.0   6696.0   2421.0       28-02-19         31-10-18  \n",
       "2   4590.0   8469.0   1185.0       25-04-18         02-04-18  \n",
       "3    492.0   6482.0  12830.0       07-11-17         08-11-18  \n",
       "4  51281.0  13434.0  18383.0       14-05-18         19-07-18  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"D:/cleaning_data/data/banking_dirty.csv\"\n",
    "banking = pd.read_csv(filepath)\n",
    "banking.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The dataset**\n",
    "<br>\n",
    "This dataset contains information about bank acounts investments.<br>\n",
    "The features are:<br>\n",
    "- ID\n",
    "- customer ID\n",
    "- customer birth date\n",
    "- customer age\n",
    "- account amount\n",
    "- investment amount\n",
    "- first fund amount\n",
    "- second fund amount\n",
    "- third fund amount\n",
    "- account open date\n",
    "- last transaction date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Where cross-field validation (CFV) can be applied?**\n",
    "<br>\n",
    "We can apply CFV to two columns:\n",
    "1. Age \n",
    "2. inv_amount\n",
    "\n",
    "**Age**\n",
    "<br>\n",
    "We can check the validity of the age by computing it manually from the birth date and check for errors\n",
    "<br> <br>\n",
    "**inv_amount**\n",
    "<br>\n",
    "We can apply CFV to the whole amount by manually sum all of the four funds and check if they sum up to the whole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. CFV for Age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1962-06-09\n",
       "1     1962-12-16\n",
       "2     1990-09-12\n",
       "3     1985-11-03\n",
       "4     1990-05-17\n",
       "         ...    \n",
       "95    1974-08-10\n",
       "96    1989-12-12\n",
       "97    1984-11-29\n",
       "98    1969-12-14\n",
       "99    1993-05-18\n",
       "Name: birth_date, Length: 100, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banking['birth_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, first, we have to convert this to datatime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "banking['birth_date'] = pd.to_datetime(banking['birth_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1962-06-09\n",
       "1    1962-12-16\n",
       "2    1990-09-12\n",
       "3    1985-11-03\n",
       "4    1990-05-17\n",
       "        ...    \n",
       "95   1974-08-10\n",
       "96   1989-12-12\n",
       "97   1984-11-29\n",
       "98   1969-12-14\n",
       "99   1993-05-18\n",
       "Name: birth_date, Length: 100, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banking['birth_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will find ages manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     58\n",
       "1     58\n",
       "2     30\n",
       "3     35\n",
       "4     30\n",
       "      ..\n",
       "95    46\n",
       "96    31\n",
       "97    36\n",
       "98    51\n",
       "99    27\n",
       "Name: birth_date, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "today = dt.date.today()\n",
    "ages_manual = (today.year - 1) - banking['birth_date'].dt.year\n",
    "ages_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find consistent and inconsistent ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_equ = ages_manual == banking['Age']\n",
    "consistent_ages = banking[age_equ]\n",
    "inconsistent_ages = banking[~age_equ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inconsistent ages:  8\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of inconsistent ages: \", inconsistent_ages.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cust_id</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>Age</th>\n",
       "      <th>acct_amount</th>\n",
       "      <th>inv_amount</th>\n",
       "      <th>fund_A</th>\n",
       "      <th>fund_B</th>\n",
       "      <th>fund_C</th>\n",
       "      <th>fund_D</th>\n",
       "      <th>account_opened</th>\n",
       "      <th>last_transaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>BFC13E88</td>\n",
       "      <td>1990-09-12</td>\n",
       "      <td>34</td>\n",
       "      <td>5.986377e+04</td>\n",
       "      <td>24567</td>\n",
       "      <td>10323.0</td>\n",
       "      <td>4590.0</td>\n",
       "      <td>8469.00</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>25-04-18</td>\n",
       "      <td>02-04-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>E52D4C7F</td>\n",
       "      <td>1975-06-05</td>\n",
       "      <td>49</td>\n",
       "      <td>6.179589e+04</td>\n",
       "      <td>49385</td>\n",
       "      <td>12939.0</td>\n",
       "      <td>7757.0</td>\n",
       "      <td>12569.00</td>\n",
       "      <td>16120.0</td>\n",
       "      <td>22-05-17</td>\n",
       "      <td>24-10-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>EEBD980F</td>\n",
       "      <td>1990-11-20</td>\n",
       "      <td>34</td>\n",
       "      <td>5.783849e+04</td>\n",
       "      <td>50812</td>\n",
       "      <td>18314.0</td>\n",
       "      <td>1477.0</td>\n",
       "      <td>29049.48</td>\n",
       "      <td>5539.0</td>\n",
       "      <td>08-12-18</td>\n",
       "      <td>04-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>A1815565</td>\n",
       "      <td>1968-09-27</td>\n",
       "      <td>56</td>\n",
       "      <td>8.299604e+04</td>\n",
       "      <td>30897</td>\n",
       "      <td>16092.0</td>\n",
       "      <td>5491.0</td>\n",
       "      <td>5098.00</td>\n",
       "      <td>4216.0</td>\n",
       "      <td>07-11-17</td>\n",
       "      <td>30-09-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>8D08495A</td>\n",
       "      <td>1961-08-14</td>\n",
       "      <td>63</td>\n",
       "      <td>8.913852e+04</td>\n",
       "      <td>60795</td>\n",
       "      <td>53880.0</td>\n",
       "      <td>1325.0</td>\n",
       "      <td>2105.00</td>\n",
       "      <td>3485.0</td>\n",
       "      <td>08-08-18</td>\n",
       "      <td>05-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>2F4F99C1</td>\n",
       "      <td>1988-12-19</td>\n",
       "      <td>36</td>\n",
       "      <td>8.205848e+04</td>\n",
       "      <td>35758</td>\n",
       "      <td>6129.0</td>\n",
       "      <td>16840.0</td>\n",
       "      <td>10397.00</td>\n",
       "      <td>2392.0</td>\n",
       "      <td>30-12-18</td>\n",
       "      <td>11-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61</td>\n",
       "      <td>45F31C81</td>\n",
       "      <td>1975-01-12</td>\n",
       "      <td>49</td>\n",
       "      <td>1.206753e+08</td>\n",
       "      <td>94608</td>\n",
       "      <td>15416.0</td>\n",
       "      <td>18845.0</td>\n",
       "      <td>20325.00</td>\n",
       "      <td>40022.0</td>\n",
       "      <td>05-11-18</td>\n",
       "      <td>25-12-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>7539C3B7</td>\n",
       "      <td>1974-05-14</td>\n",
       "      <td>50</td>\n",
       "      <td>1.077557e+06</td>\n",
       "      <td>91190</td>\n",
       "      <td>32692.0</td>\n",
       "      <td>30405.0</td>\n",
       "      <td>14728.00</td>\n",
       "      <td>13365.0</td>\n",
       "      <td>23-08-17</td>\n",
       "      <td>07-06-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0   cust_id birth_date  Age   acct_amount  inv_amount   fund_A  \\\n",
       "2            2  BFC13E88 1990-09-12   34  5.986377e+04       24567  10323.0   \n",
       "8            8  E52D4C7F 1975-06-05   49  6.179589e+04       49385  12939.0   \n",
       "12          12  EEBD980F 1990-11-20   34  5.783849e+04       50812  18314.0   \n",
       "23          23  A1815565 1968-09-27   56  8.299604e+04       30897  16092.0   \n",
       "32          32  8D08495A 1961-08-14   63  8.913852e+04       60795  53880.0   \n",
       "54          54  2F4F99C1 1988-12-19   36  8.205848e+04       35758   6129.0   \n",
       "61          61  45F31C81 1975-01-12   49  1.206753e+08       94608  15416.0   \n",
       "85          85  7539C3B7 1974-05-14   50  1.077557e+06       91190  32692.0   \n",
       "\n",
       "     fund_B    fund_C   fund_D account_opened last_transaction  \n",
       "2    4590.0   8469.00   1185.0       25-04-18         02-04-18  \n",
       "8    7757.0  12569.00  16120.0       22-05-17         24-10-19  \n",
       "12   1477.0  29049.48   5539.0       08-12-18         04-01-20  \n",
       "23   5491.0   5098.00   4216.0       07-11-17         30-09-19  \n",
       "32   1325.0   2105.00   3485.0       08-08-18         05-02-19  \n",
       "54  16840.0  10397.00   2392.0       30-12-18         11-08-18  \n",
       "61  18845.0  20325.00  40022.0       05-11-18         25-12-19  \n",
       "85  30405.0  14728.00  13365.0       23-08-17         07-06-19  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banking[~age_equ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. CFV for inv_amount**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the partial amounts columns in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_columns = ['fund_A', 'fund_B', 'fund_C', 'fund_D']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find consistent and inconsistent amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inconsistent investments:  8\n"
     ]
    }
   ],
   "source": [
    "# Find rows where fund_columns row sum == inv_amount\n",
    "inv_equ = banking[fund_columns].sum(axis = 1) == banking['inv_amount']\n",
    "\n",
    "# Store consistent and inconsistent data\n",
    "consistent_inv = banking[inv_equ]\n",
    "inconsistent_inv = banking[~inv_equ]\n",
    "\n",
    "print(\"Number of inconsistent investments: \", inconsistent_inv.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cust_id</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>Age</th>\n",
       "      <th>acct_amount</th>\n",
       "      <th>inv_amount</th>\n",
       "      <th>fund_A</th>\n",
       "      <th>fund_B</th>\n",
       "      <th>fund_C</th>\n",
       "      <th>fund_D</th>\n",
       "      <th>account_opened</th>\n",
       "      <th>last_transaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7A73F334</td>\n",
       "      <td>1990-05-17</td>\n",
       "      <td>30</td>\n",
       "      <td>120512.00</td>\n",
       "      <td>93230</td>\n",
       "      <td>12158.40</td>\n",
       "      <td>51281.00</td>\n",
       "      <td>13434.00</td>\n",
       "      <td>18383.00</td>\n",
       "      <td>14-05-18</td>\n",
       "      <td>19-07-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>EEBD980F</td>\n",
       "      <td>1990-11-20</td>\n",
       "      <td>34</td>\n",
       "      <td>57838.49</td>\n",
       "      <td>50812</td>\n",
       "      <td>18314.00</td>\n",
       "      <td>1477.00</td>\n",
       "      <td>29049.48</td>\n",
       "      <td>5539.00</td>\n",
       "      <td>08-12-18</td>\n",
       "      <td>04-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>96525DA6</td>\n",
       "      <td>1992-11-23</td>\n",
       "      <td>28</td>\n",
       "      <td>82511.24</td>\n",
       "      <td>33927</td>\n",
       "      <td>8206.00</td>\n",
       "      <td>15019.00</td>\n",
       "      <td>5559.60</td>\n",
       "      <td>6182.00</td>\n",
       "      <td>23-07-18</td>\n",
       "      <td>07-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>38B8CD9C</td>\n",
       "      <td>1970-06-25</td>\n",
       "      <td>50</td>\n",
       "      <td>28834.71</td>\n",
       "      <td>27531</td>\n",
       "      <td>314.00</td>\n",
       "      <td>6072.28</td>\n",
       "      <td>14163.00</td>\n",
       "      <td>7908.00</td>\n",
       "      <td>17-09-18</td>\n",
       "      <td>05-02-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>68C55974</td>\n",
       "      <td>1962-07-08</td>\n",
       "      <td>58</td>\n",
       "      <td>95038.14</td>\n",
       "      <td>66796</td>\n",
       "      <td>33764.00</td>\n",
       "      <td>5042.00</td>\n",
       "      <td>10659.00</td>\n",
       "      <td>19237.41</td>\n",
       "      <td>03-04-18</td>\n",
       "      <td>25-09-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>0A9BA907</td>\n",
       "      <td>1966-09-21</td>\n",
       "      <td>54</td>\n",
       "      <td>90469.53</td>\n",
       "      <td>70171</td>\n",
       "      <td>28615.00</td>\n",
       "      <td>21720.05</td>\n",
       "      <td>11906.00</td>\n",
       "      <td>10763.00</td>\n",
       "      <td>15-06-18</td>\n",
       "      <td>28-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>89</td>\n",
       "      <td>C580AE41</td>\n",
       "      <td>1968-06-01</td>\n",
       "      <td>52</td>\n",
       "      <td>96673.37</td>\n",
       "      <td>68466</td>\n",
       "      <td>8489.36</td>\n",
       "      <td>28592.00</td>\n",
       "      <td>2439.00</td>\n",
       "      <td>30419.00</td>\n",
       "      <td>28-09-18</td>\n",
       "      <td>17-09-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>A07D5C92</td>\n",
       "      <td>1990-09-20</td>\n",
       "      <td>30</td>\n",
       "      <td>99577.36</td>\n",
       "      <td>60407</td>\n",
       "      <td>6467.00</td>\n",
       "      <td>20861.00</td>\n",
       "      <td>9861.00</td>\n",
       "      <td>26004.16</td>\n",
       "      <td>17-11-17</td>\n",
       "      <td>16-01-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0   cust_id birth_date  Age  acct_amount  inv_amount    fund_A  \\\n",
       "4            4  7A73F334 1990-05-17   30    120512.00       93230  12158.40   \n",
       "12          12  EEBD980F 1990-11-20   34     57838.49       50812  18314.00   \n",
       "22          22  96525DA6 1992-11-23   28     82511.24       33927   8206.00   \n",
       "43          43  38B8CD9C 1970-06-25   50     28834.71       27531    314.00   \n",
       "47          47  68C55974 1962-07-08   58     95038.14       66796  33764.00   \n",
       "65          65  0A9BA907 1966-09-21   54     90469.53       70171  28615.00   \n",
       "89          89  C580AE41 1968-06-01   52     96673.37       68466   8489.36   \n",
       "92          92  A07D5C92 1990-09-20   30     99577.36       60407   6467.00   \n",
       "\n",
       "      fund_B    fund_C    fund_D account_opened last_transaction  \n",
       "4   51281.00  13434.00  18383.00       14-05-18         19-07-18  \n",
       "12   1477.00  29049.48   5539.00       08-12-18         04-01-20  \n",
       "22  15019.00   5559.60   6182.00       23-07-18         07-08-18  \n",
       "43   6072.28  14163.00   7908.00       17-09-18         05-02-20  \n",
       "47   5042.00  10659.00  19237.41       03-04-18         25-09-18  \n",
       "65  21720.05  11906.00  10763.00       15-06-18         28-08-18  \n",
       "89  28592.00   2439.00  30419.00       28-09-18         17-09-18  \n",
       "92  20861.00   9861.00  26004.16       17-11-17         16-01-20  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banking[~inv_equ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What to do with inconsistencies?\n",
    "There is no *one size fits all* solution, the best solution requires an in-depth understanding of the dataset.<br>\n",
    "We can decide to either<br>\n",
    "- drop inconsistent data\n",
    "- deal with inconsistent data as missing and impute them\n",
    "- apply some rules due to domain knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That's it!\n",
    "## Share this with others!\n",
    "#### Ibrahim M. Nasser"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
